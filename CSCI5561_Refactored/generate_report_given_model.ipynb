{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf42d78",
   "metadata": {},
   "source": [
    "Bin's comment:\n",
    "\n",
    "**NOT COMPLETED**\n",
    "\n",
    "Last modified on 4/13"
   ]
  },
  {
   "cell_type": "raw",
   "id": "317bd0c1",
   "metadata": {},
   "source": [
    "***This block is not code\n",
    "***Read before running the notebook\n",
    "\n",
    "CREATE folder paths manually as:\n",
    "ROOT\n",
    "    |-model\n",
    "    |\n",
    "    |-dataset\n",
    "    |    |-X_train_input\n",
    "    |    |-X_train_target\n",
    "    |    |-X_test_input\n",
    "    |    |-X_test_target\n",
    "    |\n",
    "    |-main.ipynb\n",
    "    |\n",
    "    |-discarded_code\n",
    "\n",
    "The dataset is from:\n",
    "https://www.kaggle.com/datasets/sanglequang/brats-2018-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2200658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:20.561031Z",
     "start_time": "2023-04-24T08:32:19.185721Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet4(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=5, bilinear=False):\n",
    "        super(UNet4, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "class UNet3(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=5, bilinear=False):\n",
    "        super(UNet3, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.up1 = Up(512, 256 // factor, bilinear)\n",
    "        self.up2 = Up(256, 128 // factor, bilinear)\n",
    "        self.up3 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddfb74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.313200Z",
     "start_time": "2023-04-24T08:32:20.563031Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import SimpleITK as sitk\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras.models import load_model\n",
    "denoising_model = load_model('denoising-model', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456a6559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.361211Z",
     "start_time": "2023-04-24T08:32:21.314200Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    batch_size = 16\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    epochs = 6\n",
    "    warmup = 0.1\n",
    "    lr = 1e-5\n",
    "    T_0 = 100  # period of the first restart, we do not want it to restart, so we set it a big number\n",
    "    T_mult = 1  # period multiplier, it does not matter\n",
    "    eta_min = lr/10  # minimum learning rate\n",
    "    len_train_dataloader = None\n",
    "    len_valid_dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb02826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.377215Z",
     "start_time": "2023-04-24T08:32:21.362211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set SEED here # to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fdf42b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.393219Z",
     "start_time": "2023-04-24T08:32:21.378215Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset'\n",
    "TRAIN_X_PATH = os.path.join(DATASET_PATH, 'X_train_input')\n",
    "VALID_X_PATH = os.path.join(DATASET_PATH, 'X_test_input')\n",
    "TRAIN_Y_PATH = os.path.join(DATASET_PATH, 'X_train_target')\n",
    "VALID_Y_PATH = os.path.join(DATASET_PATH, 'X_test_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84398280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.441229Z",
     "start_time": "2023-04-24T08:32:21.394218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(os.listdir(TRAIN_X_PATH))\n",
    "Config.len_train_dataloader = len_train//Config.batch_size\n",
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ed641c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.473236Z",
     "start_time": "2023-04-24T08:32:21.442229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_valid = len(os.listdir(VALID_X_PATH))\n",
    "Config.len_valid_dataloader = len_valid//Config.batch_size\n",
    "len_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c5a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T01:16:15.971437Z",
     "start_time": "2023-04-13T01:16:15.964435Z"
    }
   },
   "source": [
    "The index of TRAIN SET ranges from 0 to 35339 (end included)\n",
    "\n",
    "The index of VALID SET ranges from 0 to 8834 (end included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ccbaaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.489240Z",
     "start_time": "2023-04-24T08:32:21.474237Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_loader(mode, x_or_y, index):\n",
    "    \"\"\"\n",
    "    Return the numpy image given the information.\n",
    "    mode: 'train', 'valid' or 'test'\n",
    "    x_or_y: 'x' or 'y', 'x' stands for the input and 'y' stands for the target\n",
    "    index: int, the index of the image\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        if x_or_y == 'x':\n",
    "            filepath = os.path.join(TRAIN_X_PATH, os.path.basename(TRAIN_X_PATH)+'_'+str(index)+'.npy')\n",
    "        if x_or_y == 'y':\n",
    "            filepath = os.path.join(TRAIN_Y_PATH, os.path.basename(TRAIN_Y_PATH)+'_'+str(index)+'.npy')\n",
    "    elif mode == 'valid':\n",
    "        if x_or_y == 'x':\n",
    "            filepath = os.path.join(VALID_X_PATH, os.path.basename(VALID_X_PATH)+'_'+str(index)+'.npy')\n",
    "        if x_or_y == 'y':\n",
    "            filepath = os.path.join(VALID_Y_PATH, os.path.basename(VALID_Y_PATH)+'_'+str(index)+'.npy')\n",
    "    else:\n",
    "        raise ValueError(\"The first or the second parameter is not valid\")\n",
    "        \n",
    "    if not isinstance(index, int):\n",
    "        raise TypeError(\"Index should be an integer\")\n",
    "    \n",
    "    if mode == 'train' and (index < 0 or index > 35339):\n",
    "            raise IndexError(\"Image index out of range 0 - 35339\")\n",
    "            \n",
    "    if mode == 'valid' and (index < 0 or index > 8834):\n",
    "            raise IndexError(\"Image index out of range 0 - 8834\")\n",
    "    \n",
    "    return np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0cc773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.505243Z",
     "start_time": "2023-04-24T08:32:21.491240Z"
    }
   },
   "outputs": [],
   "source": [
    "img_example = image_loader('valid', 'y', 560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a9d38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.633272Z",
     "start_time": "2023-04-24T08:32:21.506244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26b87bbdd90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971e057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2e36a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.649275Z",
     "start_time": "2023-04-24T08:32:21.634272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader('train', 'y', 6164).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ca0a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.665280Z",
     "start_time": "2023-04-24T08:32:21.650275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader('train', 'x', 6164).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f521a6",
   "metadata": {},
   "source": [
    "**Bin's comment:**\n",
    "\n",
    "SimpleITK is a widely used package to transform medical images\n",
    "\n",
    "\n",
    "I dont know whether it is slower than other packages like torchvision transform\n",
    "You may define other transformation functions and compare them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d2643",
   "metadata": {},
   "source": [
    "##### Tony's Comment:\n",
    "Pytorch seems to work best for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd62339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.681283Z",
     "start_time": "2023-04-24T08:32:21.667280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pytorch version\n",
    "# --------------------\n",
    "# This version is fast and more reliable than SITK version\n",
    "# Applies several random tansformations to an image and the label\n",
    "# - Gaussian blur : image only\n",
    "# - Rotation : image and label\n",
    "# - Translation : image and label\n",
    "def transform(input_array, label_array):\n",
    "    \"\"\"\n",
    "    Data augmentation for training set.\n",
    "    input_array, label_array are in ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # pytorch likes input to be in [C, H, W]\n",
    "        input_layers = [input_array[i,:,:] for i in range(input_array.shape[0])]\n",
    "        label_layers = [label_array]\n",
    "        stacked_layers = np.array(input_layers + label_layers)\n",
    "        stacked_tensor = torch.tensor(stacked_layers)\n",
    "\n",
    "        # Gaussian blur\n",
    "        blurT = torchvision.transforms.GaussianBlur(kernel_size=5, sigma=(0.01, 1))\n",
    "        # transformed = blurT.forward(input_tensor).numpy()\n",
    "\n",
    "        # slight rotation\n",
    "        rotationT = torchvision.transforms.RandomRotation(degrees = (-5,5))\n",
    "        # transformed = rotationT.forward(input_tensor).numpy()\n",
    "\n",
    "        # slight translation\n",
    "        translateT = torchvision.transforms.RandomAffine(degrees=0, translate=(0.0, 0.05))\n",
    "        # transformed = translateT.forward(input_tensor).numpy()\n",
    "\n",
    "        # apply transformations\n",
    "        combinedT = torchvision.transforms.Compose([rotationT, translateT])\n",
    "        transformed_stacked = combinedT(stacked_tensor)\n",
    "        transformed_input = transformed_stacked[0:-1, :,:]\n",
    "        transformed_input = blurT.forward(transformed_input).numpy() # add blur to input\n",
    "        transformed_label = transformed_stacked[-1, :,:].numpy()\n",
    "\n",
    "        # # turn back into original shape\n",
    "        # transformed_input_orig = np.array([[transformed_input[:,i,j] for j in range(transformed_input.shape[2])] for i in range(transformed_input.shape[1])])\n",
    "    \n",
    "    except:\n",
    "        transformed_input = input_array\n",
    "        transformed_label = label_array\n",
    "\n",
    "    return transformed_input, transformed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94586df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:21.697287Z",
     "start_time": "2023-04-24T08:32:21.682284Z"
    }
   },
   "outputs": [],
   "source": [
    "# SimpleITK Version\n",
    "# ------------------\n",
    "# Broken: Use the pytorch version unless this one gets fixed\n",
    "def transformITK(input_array, label_array):\n",
    "    \"\"\"\n",
    "    Data augmentation for training set.\n",
    "    input_array, label_array are in ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    # stack input and label so they can be modified togther\n",
    "    stacked = np.zeros((input_array.shape[0], input_array.shape[1], input_array.shape[2] + 1))\n",
    "    stacked[:,:,:-1] = input_array\n",
    "    stacked[:,:,-1] = label_array\n",
    "\n",
    "    # transform to simpleITK image\n",
    "    image = sitk.GetImageFromArray(stacked)\n",
    "\n",
    "    # get info about image\n",
    "    width, height, depth = image.GetSize()\n",
    "    image_center =  image.TransformIndexToPhysicalPoint((int(np.ceil(width/2)),\n",
    "                                          int(np.ceil(height/2)),\n",
    "                                          int(np.ceil(depth/2))))\n",
    "\n",
    "    # set transformation parameters\n",
    "    sigma_max = 0.01\n",
    "    sigma_min = 1\n",
    "    rot_max = -5 # in degrees\n",
    "    rot_min = 5 # in degrees\n",
    "    trnsl_x_max = 0.5\n",
    "    trnsl_x_min = -0.5\n",
    "    trnsl_y_max = 0.5\n",
    "    trnsl_y_min = -0.5\n",
    "\n",
    "    sigma = (sigma_max - sigma_min) * np.random.random_sample() + sigma_min\n",
    "    random_degree = (rot_max - rot_min) * np.random.random_sample() + rot_min\n",
    "    random_x = (trnsl_x_max - trnsl_x_min) * np.random.random_sample() + trnsl_x_min\n",
    "    random_y = (trnsl_y_max - trnsl_y_min) * np.random.random_sample() + trnsl_y_min\n",
    "    translation = (random_x, random_y, 0)\n",
    "\n",
    "    # preform rotation and translation on both\n",
    "    rotation_angle = np.deg2rad(random_degree)\n",
    "    euler_transform = sitk.Euler3DTransform(image_center, rotation_angle, 0, 0, translation)\n",
    "    reference_image = image\n",
    "    interpolator = sitk.sitkBSpline\n",
    "    default_value = 0\n",
    "    transformed = sitk.Resample(image, reference_image, euler_transform,\n",
    "                     interpolator, default_value)\n",
    "\n",
    "    # seperate input and label\n",
    "    transformed_stacked = sitk.GetArrayFromImage(transformed)\n",
    "    transformed_input = transformed_stacked[:,:,0:-1]\n",
    "    transformed_label = transformed_stacked[:,:,-1]\n",
    "\n",
    "    # preform gaussion blur on only input\n",
    "    input_image = sitk.GetImageFromArray(transformed_input)\n",
    "    gaussian = sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "    gaussian.SetSigma(sigma)\n",
    "    transformed_image = gaussian.Execute(input_image)\n",
    "    \n",
    "    # turn back into numpy array\n",
    "    transformed_input = sitk.GetArrayFromImage(transformed_image)\n",
    "    \n",
    "    return transformed_input, transformed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "314e6821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.540377Z",
     "start_time": "2023-04-24T08:32:21.698287Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    img = image_loader('train', 'x', idx)\n",
    "    label = image_loader('train', 'y', idx)\n",
    "    img_reordered = img.transpose((2, 0, 1))\n",
    "    # print(img_reordered.shape)\n",
    "    # print(label.shape)\n",
    "    # print(img.dtype)\n",
    "    transformed_input, transformed_label = transform(img_reordered, label)\n",
    "    # print(transformed_input.shape)\n",
    "    # print(transformed_label.shape)\n",
    "    # transformed_inputITK, transformed_labelITK = transformITK(img, label)\n",
    "\n",
    "    # turn back into original shape\n",
    "    transformed_input_orig = np.array([[transformed_input[:,i,j] for j in range(transformed_input.shape[2])] for i in range(transformed_input.shape[1])])\n",
    "    # print(transformed_input_orig.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226e9370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.876454Z",
     "start_time": "2023-04-24T08:32:26.541378Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,3,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(transformed_input_orig)\n",
    "plt.title(\"Pytorch Image\")\n",
    "\n",
    "# plt.subplot(2,3,3)\n",
    "# plt.imshow(transformed_inputITK)\n",
    "# plt.title(\"SITK Image\")\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(label)\n",
    "plt.title(\"Original Label\")\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(transformed_label)\n",
    "plt.title(\"Pytorch Label\")\n",
    "\n",
    "# plt.subplot(2,3,6)\n",
    "# plt.imshow(transformed_labelITK)\n",
    "# plt.title(\"SITK Label\")\n",
    "\n",
    "plt.suptitle(\"Data Augmentation Demo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02918ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.892457Z",
     "start_time": "2023-04-24T08:32:26.877454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(type(transformed_input))\n",
    "print(transformed_input.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96748154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.908461Z",
     "start_time": "2023-04-24T08:32:26.893458Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len_train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = image_loader('train', 'x', idx), image_loader('train', 'y', idx)\n",
    "        x = denoising_model.predict(np.array([x]))[0]\n",
    "        x = x.transpose((2, 0, 1))\n",
    "        x, y = transform(x, y)\n",
    "        return x, y # NOTE the permute, => Batch*Channel*Wright*Height\n",
    "    \n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len_valid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = image_loader('valid', 'x', idx), image_loader('valid', 'y', idx)\n",
    "        x = denoising_model.predict(np.array([x]))[0]\n",
    "        x = x.transpose((2, 0, 1))\n",
    "        return x,y\n",
    "\n",
    "train_dataset = TrainDataset()\n",
    "valid_dataset = ValidDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=Config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5bf5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.924465Z",
     "start_time": "2023-04-24T08:32:26.909461Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test the model\n",
    "#net = UNet3(4, 5) # 4 channels, 5 classes (label 3 actually is ingored)\n",
    "#y = net(torch.randn(8,4,240,240))\n",
    "#_, y = torch.max(y, 1)\n",
    "#print(y.size())\n",
    "#del net, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e99060d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:32:26.940468Z",
     "start_time": "2023-04-24T08:32:26.925464Z"
    }
   },
   "outputs": [],
   "source": [
    "#The F1 score is the Dice coefficient of the set of retrieved items and the set of relevant items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5018b547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:43:04.900349Z",
     "start_time": "2023-04-24T08:32:26.941468Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background      0.997     0.995     0.996 502465142\n",
      "     NCR/NET      0.503     0.511     0.507   1632930\n",
      "          ED      0.429     0.531     0.474   3624115\n",
      "          ET      0.441     0.571     0.498   1173813\n",
      "\n",
      "    accuracy                          0.989 508896000\n",
      "   macro avg      0.592     0.652     0.619 508896000\n",
      "weighted avg      0.990     0.989     0.989 508896000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "device=Config.device\n",
    "\n",
    "#model = UNet4(4,5)\n",
    "#model = model.load_state_dict(torch.load('UNet4, Epoch5, loss 0p0721.pt'))\n",
    "\n",
    "model = UNet4()\n",
    "model = torch.load('UNet4, Epoch5, loss 0p0721.pt')\n",
    "\n",
    "\n",
    "bestLoss = 1000000\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_pred = []\n",
    "        total_target = []\n",
    "        for j, (inputs, targets) in enumerate(valid_dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.type(torch.LongTensor).to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            result = torch.argmax(outputs.detach(), dim=1)\n",
    "            \n",
    "            pred_numpy=result.cpu().numpy().flatten().tolist()\n",
    "            target_numpy=targets.cpu().numpy().flatten().tolist()\n",
    "            total_pred.append(pred_numpy)\n",
    "            total_target.append(target_numpy)\n",
    "            \n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "total_pred = np.concatenate(total_pred)\n",
    "total_target = np.concatenate(total_target)\n",
    "\n",
    "\n",
    "report = classification_report(total_target, total_pred, digits=3, target_names = ['Background', 'NCR/NET', 'ED', 'ET'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deacbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "10b3d560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T08:09:33.320914Z",
     "start_time": "2023-04-24T07:57:10.812Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "device=Config.device\n",
    "\n",
    "model = UNet4(4,5)\n",
    "model = torch.load('UNET4, no transformation, Epoch 6, loss 0p0604.pt')\n",
    "bestLoss = 1000000\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_pred = []\n",
    "        total_target = []\n",
    "        for j, (inputs, targets) in enumerate(valid_dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.type(torch.LongTensor).to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            result = torch.argmax(outputs.detach(), dim=1)\n",
    "            \n",
    "            pred_numpy=result.cpu().numpy().flatten().tolist()\n",
    "            target_numpy=targets.cpu().numpy().flatten().tolist()\n",
    "            total_pred.append(pred_numpy)\n",
    "            total_target.append(target_numpy)\n",
    "\n",
    "total_pred = np.concatenate(total_pred)\n",
    "total_target = np.concatenate(total_target)\n",
    "\n",
    "\n",
    "report = classification_report(total_target, total_pred, digits=3, target_names = ['Background', 'NCR/NET', 'ED', 'ET'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5252273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:44:32.770459Z",
     "start_time": "2023-04-23T09:44:19.361Z"
    }
   },
   "source": [
    "# reshape test\n",
    "idx = 6164\n",
    "img = image_loader('train', 'x', idx)\n",
    "\n",
    "# long way (ground truth)\n",
    "c0 = img[:,:,0]\n",
    "c1 = img[:,:,1]\n",
    "c2 = img[:,:,2]\n",
    "c3 = img[:,:,3]\n",
    "input_array = np.array([c0,c1,c2,c3])\n",
    "\n",
    "print(input_array.shape)\n",
    "\n",
    "# short way (experimental)\n",
    "test = np.array([img[:,:,i] for i in range(img.shape[2])])\n",
    "\n",
    "# test for equality\n",
    "print(np.sum(1*(input_array != test)))\n",
    "\n",
    "# now go back\n",
    "orig = np.array([[test[:,i,j] for j in range(test.shape[2])] for i in range(test.shape[1])])\n",
    "# orig = test.reshape(img.shape)\n",
    "\n",
    "# test for equality\n",
    "print(np.sum(1*(orig != img)))\n",
    "\n",
    "1*(orig != img)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da578b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:44:32.771459Z",
     "start_time": "2023-04-23T09:44:19.362Z"
    }
   },
   "source": [
    "# reshape testing\n",
    "#a = np.array([[[1,2],[4,5]],[[7,8],[10,11]]])\n",
    "#b = np.array([[3,6],[9,12]])\n",
    "#c = np.zeros((a.shape[0], a.shape[1], a.shape[2] + 1))\n",
    "#c[:,:,:-1] = a\n",
    "#c[:,:,-1] = b\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc18754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef2162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
